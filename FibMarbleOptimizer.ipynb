{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM4rpMtZKWMt",
        "outputId": "aa119a00-f1b3-489f-deac-bb1b85ac03d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with Enhanced FibMarble V3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 1: 100%|██████████| 938/938 [00:29<00:00, 32.19it/s, loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 1 | Train Loss: 0.5450 | Test Loss: 0.2514 | Accuracy: 92.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 2: 100%|██████████| 938/938 [00:32<00:00, 29.30it/s, loss=0.449]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 2 | Train Loss: 0.2290 | Test Loss: 0.1969 | Accuracy: 94.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 3: 100%|██████████| 938/938 [00:32<00:00, 29.22it/s, loss=0.0204]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 3 | Train Loss: 0.1684 | Test Loss: 0.1604 | Accuracy: 95.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 4: 100%|██████████| 938/938 [00:33<00:00, 28.42it/s, loss=0.131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 4 | Train Loss: 0.1379 | Test Loss: 0.1339 | Accuracy: 95.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 5: 100%|██████████| 938/938 [00:32<00:00, 29.18it/s, loss=0.232]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 5 | Train Loss: 0.1291 | Test Loss: 0.1381 | Accuracy: 95.81%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 6: 100%|██████████| 938/938 [00:32<00:00, 28.93it/s, loss=0.271]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 6 | Train Loss: 0.1220 | Test Loss: 0.1349 | Accuracy: 95.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 7: 100%|██████████| 938/938 [00:32<00:00, 29.17it/s, loss=0.00426]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 7 | Train Loss: 0.1158 | Test Loss: 0.1298 | Accuracy: 96.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 8: 100%|██████████| 938/938 [00:32<00:00, 29.26it/s, loss=0.205]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 8 | Train Loss: 0.1185 | Test Loss: 0.1203 | Accuracy: 96.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 9: 100%|██████████| 938/938 [00:33<00:00, 28.10it/s, loss=0.0164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 9 | Train Loss: 0.1143 | Test Loss: 0.1164 | Accuracy: 96.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FibMarble V3 Epoch 10: 100%|██████████| 938/938 [00:33<00:00, 27.87it/s, loss=0.0505]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FibMarble V3] Epoch 10 | Train Loss: 0.1146 | Test Loss: 0.1219 | Accuracy: 96.37%\n",
            "\n",
            "Training with Adam...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 1: 100%|██████████| 938/938 [00:22<00:00, 41.36it/s, loss=0.014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 1 | Train Loss: 0.2333 | Test Loss: 0.1176 | Accuracy: 96.49%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 2: 100%|██████████| 938/938 [00:22<00:00, 40.99it/s, loss=0.172]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 2 | Train Loss: 0.0963 | Test Loss: 0.0844 | Accuracy: 97.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 3: 100%|██████████| 938/938 [00:22<00:00, 40.85it/s, loss=0.132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 3 | Train Loss: 0.0648 | Test Loss: 0.0815 | Accuracy: 97.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 4: 100%|██████████| 938/938 [00:22<00:00, 41.19it/s, loss=0.0046]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 4 | Train Loss: 0.0507 | Test Loss: 0.0779 | Accuracy: 97.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 5: 100%|██████████| 938/938 [00:22<00:00, 42.10it/s, loss=0.0379]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 5 | Train Loss: 0.0379 | Test Loss: 0.1029 | Accuracy: 96.97%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 6: 100%|██████████| 938/938 [00:22<00:00, 42.31it/s, loss=0.00786]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 6 | Train Loss: 0.0322 | Test Loss: 0.1043 | Accuracy: 96.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 7: 100%|██████████| 938/938 [00:22<00:00, 42.23it/s, loss=0.0445]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 7 | Train Loss: 0.0285 | Test Loss: 0.0841 | Accuracy: 97.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 8: 100%|██████████| 938/938 [00:22<00:00, 42.36it/s, loss=0.0931]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 8 | Train Loss: 0.0229 | Test Loss: 0.1023 | Accuracy: 97.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 9: 100%|██████████| 938/938 [00:22<00:00, 42.29it/s, loss=0.00136]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 9 | Train Loss: 0.0229 | Test Loss: 0.0821 | Accuracy: 98.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Adam Epoch 10: 100%|██████████| 938/938 [00:22<00:00, 42.11it/s, loss=0.0125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Adam] Epoch 10 | Train Loss: 0.0166 | Test Loss: 0.0831 | Accuracy: 98.04%\n",
            "\n",
            "Training with SGD+Momentum...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 1: 100%|██████████| 938/938 [00:21<00:00, 43.67it/s, loss=0.0993]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 1 | Train Loss: 0.3076 | Test Loss: 0.1296 | Accuracy: 96.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 2: 100%|██████████| 938/938 [00:21<00:00, 42.85it/s, loss=0.00585]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 2 | Train Loss: 0.1063 | Test Loss: 0.0923 | Accuracy: 97.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 3: 100%|██████████| 938/938 [00:21<00:00, 43.06it/s, loss=0.212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 3 | Train Loss: 0.0689 | Test Loss: 0.0764 | Accuracy: 97.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 4: 100%|██████████| 938/938 [00:21<00:00, 43.16it/s, loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 4 | Train Loss: 0.0491 | Test Loss: 0.0782 | Accuracy: 97.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 5: 100%|██████████| 938/938 [00:21<00:00, 43.33it/s, loss=0.00799]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 5 | Train Loss: 0.0369 | Test Loss: 0.0765 | Accuracy: 97.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 6: 100%|██████████| 938/938 [00:21<00:00, 44.60it/s, loss=0.0463]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 6 | Train Loss: 0.0264 | Test Loss: 0.0700 | Accuracy: 97.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 7: 100%|██████████| 938/938 [00:21<00:00, 44.51it/s, loss=0.0148]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 7 | Train Loss: 0.0195 | Test Loss: 0.0669 | Accuracy: 97.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 8: 100%|██████████| 938/938 [00:21<00:00, 43.53it/s, loss=0.00406]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 8 | Train Loss: 0.0148 | Test Loss: 0.0670 | Accuracy: 97.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 9: 100%|██████████| 938/938 [00:21<00:00, 43.14it/s, loss=0.0149]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SGD+Momentum] Epoch 9 | Train Loss: 0.0101 | Test Loss: 0.0683 | Accuracy: 98.02%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SGD+Momentum Epoch 10: 100%|██████████| 938/938 [00:21<00:00, 43.35it/s, loss=0.011]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Enhanced FibMarble Optimizer V3 ---\n",
        "class FibMarbleOptimizerV3(torch.optim.Optimizer):\n",
        "    def __init__(self, params, lr=0.01, beta=0.9, max_spin=0.3, min_spin=0.01,\n",
        "                 angle_decay=0.97, friction=0.01, fib_period=8, max_speed=1.0, min_speed=0.01):\n",
        "        defaults = dict(lr=lr, beta=beta, max_spin=max_spin, min_spin=min_spin,\n",
        "                       angle_decay=angle_decay, friction=friction,\n",
        "                       fib_period=fib_period, max_speed=max_speed, min_speed=min_speed)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "        # Initialize Fibonacci sequence with enough values\n",
        "        self.fib_period = fib_period\n",
        "        self.fib_seq = [1, 1]\n",
        "        while len(self.fib_seq) < fib_period:\n",
        "            self.fib_seq.append(self.fib_seq[-1] + self.fib_seq[-2])\n",
        "\n",
        "        self.step_count = 0\n",
        "        self.base_angle = math.pi / 4  # 45° for balanced exploration\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        self.step_count += 1\n",
        "\n",
        "        # Ensure Fibonacci sequence is long enough\n",
        "        if self.step_count >= len(self.fib_seq):\n",
        "            next_val = min(self.fib_seq[-1] + self.fib_seq[-2], 1000)\n",
        "            self.fib_seq.append(next_val)\n",
        "\n",
        "        fib_ratio = self.fib_seq[self.step_count] / (self.fib_seq[self.step_count-1] + 1e-8)\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            # Fibonacci-aware learning rate adjustment\n",
        "            cycle_pos = self.step_count % group['fib_period']\n",
        "            fib_idx = min(cycle_pos, len(self.fib_seq)-1)\n",
        "            current_lr = group['lr'] * (self.fib_seq[fib_idx] / self.fib_seq[group['fib_period']-1])\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "\n",
        "                # Initialize state\n",
        "                if 'momentum_buffer' not in state:\n",
        "                    state['momentum_buffer'] = torch.zeros_like(p.data)\n",
        "                    state['grad_var'] = torch.zeros_like(p.data)\n",
        "                    state['spin_buffer'] = torch.zeros_like(p.data)\n",
        "                    state['prev_grad'] = torch.zeros_like(p.data)\n",
        "                    if group['max_spin'] > 0:  # Only initialize if using spin\n",
        "                        state['angular_momentum'] = torch.zeros_like(p.data)\n",
        "\n",
        "                # Adaptive spin calculation\n",
        "                grad_var = state['grad_var']\n",
        "                grad_var.mul_(group['beta']).addcmul_(grad, grad, value=1-group['beta'])\n",
        "\n",
        "                # Normalized spin strength (0-1 range)\n",
        "                spin_strength = (grad_var / (grad_var.mean() + 1e-8)).clamp(0, 1)\n",
        "                current_spin = group['min_spin'] + (group['max_spin'] - group['min_spin']) * spin_strength\n",
        "\n",
        "                # Update momentum with friction\n",
        "                state['momentum_buffer'].mul_(group['beta'] * (1 - group['friction'])).add_(grad)\n",
        "\n",
        "                # Gradient-angle correlated spin\n",
        "                grad_change = grad - state['prev_grad']\n",
        "                spin_direction = torch.sign(grad_change) * torch.sign(grad)\n",
        "                state['spin_buffer'] = group['beta'] * state['spin_buffer'] + \\\n",
        "                                      current_spin * spin_direction * grad.norm()\n",
        "                state['prev_grad'] = grad.clone()\n",
        "\n",
        "                # Apply update with current angle\n",
        "                angle = self.base_angle * (group['angle_decay'] ** self.step_count)\n",
        "                update = -current_lr * fib_ratio * (\n",
        "                    state['momentum_buffer'] * math.cos(angle) +\n",
        "                    state['spin_buffer'] * math.sin(angle)\n",
        "                )\n",
        "\n",
        "                # Physical constraints\n",
        "                update_norm = update.norm()\n",
        "                if update_norm > group['max_speed']:\n",
        "                    update.mul_(group['max_speed'] / (update_norm + 1e-8))\n",
        "                elif update_norm < group['min_speed']:\n",
        "                    update.mul_(group['min_speed'] / (update_norm + 1e-8))\n",
        "\n",
        "                # Hybrid mode for small gradients\n",
        "                if grad.abs().max() < 0.01 and group['max_spin'] > 0:\n",
        "                    if 'adam_m' not in state:\n",
        "                        state['adam_m'] = torch.zeros_like(p.data)\n",
        "                        state['adam_v'] = torch.zeros_like(p.data)\n",
        "\n",
        "                    state['adam_m'].mul_(group['beta']).add_(grad, alpha=1-group['beta'])\n",
        "                    state['adam_v'].mul_(group['beta']).addcmul_(grad, grad, value=1-group['beta'])\n",
        "\n",
        "                    m_hat = state['adam_m'] / (1 - group['beta']**self.step_count)\n",
        "                    v_hat = state['adam_v'] / (1 - group['beta']**self.step_count)\n",
        "\n",
        "                    update = -current_lr * m_hat / (torch.sqrt(v_hat) + 1e-8)\n",
        "\n",
        "                p.data.add_(update)\n",
        "\n",
        "# --- Simple Feedforward Network ---\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# --- Training Function with Progress Bar ---\n",
        "def train(model, optimizer, train_loader, test_loader, epochs=10, name=\"\"):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    acc_list, loss_list = [], []\n",
        "    test_acc_list, test_loss_list = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"{name} Epoch {epoch+1}\")\n",
        "\n",
        "        for images, labels in progress_bar:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images)\n",
        "                test_loss += criterion(outputs, labels).item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        test_avg_loss = test_loss / len(test_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        acc_list.append(accuracy)\n",
        "        loss_list.append(avg_loss)\n",
        "        test_acc_list.append(accuracy)\n",
        "        test_loss_list.append(test_avg_loss)\n",
        "\n",
        "        print(f\"[{name}] Epoch {epoch+1} | \"\n",
        "              f\"Train Loss: {avg_loss:.4f} | Test Loss: {test_avg_loss:.4f} | \"\n",
        "              f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    return acc_list, loss_list, test_acc_list, test_loss_list\n",
        "\n",
        "# --- Data Loaders ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# --- Training Setup ---\n",
        "def reset_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        m.reset_parameters()\n",
        "\n",
        "# --- Train with Enhanced FibMarble V3 ---\n",
        "model_fib = SimpleNN()\n",
        "model_fib.apply(reset_weights)\n",
        "optimizer_fib = FibMarbleOptimizerV3(\n",
        "    model_fib.parameters(),\n",
        "    lr=0.01,\n",
        "    beta=0.9,\n",
        "    max_spin=0.3,\n",
        "    min_spin=0.01,\n",
        "    angle_decay=0.97,\n",
        "    friction=0.01,\n",
        "    fib_period=8,\n",
        "    max_speed=1.0,\n",
        "    min_speed=0.01\n",
        ")\n",
        "print(\"\\nTraining with Enhanced FibMarble V3...\")\n",
        "acc_fib, loss_fib, test_acc_fib, test_loss_fib = train(\n",
        "    model_fib, optimizer_fib, train_loader, test_loader, name=\"FibMarble V3\"\n",
        ")\n",
        "\n",
        "# --- Train with Adam ---\n",
        "model_adam = SimpleNN()\n",
        "model_adam.apply(reset_weights)\n",
        "optimizer_adam = torch.optim.Adam(model_adam.parameters(), lr=0.001)\n",
        "print(\"\\nTraining with Adam...\")\n",
        "acc_adam, loss_adam, test_acc_adam, test_loss_adam = train(\n",
        "    model_adam, optimizer_adam, train_loader, test_loader, name=\"Adam\"\n",
        ")\n",
        "\n",
        "# --- Train with SGD with Momentum ---\n",
        "model_sgd = SimpleNN()\n",
        "model_sgd.apply(reset_weights)\n",
        "optimizer_sgd = torch.optim.SGD(model_sgd.parameters(), lr=0.01, momentum=0.9)\n",
        "print(\"\\nTraining with SGD+Momentum...\")\n",
        "acc_sgd, loss_sgd, test_acc_sgd, test_loss_sgd = train(\n",
        "    model_sgd, optimizer_sgd, train_loader, test_loader, name=\"SGD+Momentum\"\n",
        ")\n",
        "\n",
        "# --- Print Final Results ---\n",
        "print(\"\\nFinal Results:\")\n",
        "print(f\"FibMarble V3 - Test Accuracy: {test_acc_fib[-1]:.2f}% | Test Loss: {test_loss_fib[-1]:.4f}\")\n",
        "print(f\"Adam         - Test Accuracy: {test_acc_adam[-1]:.2f}% | Test Loss: {test_loss_adam[-1]:.4f}\")\n",
        "print(f\"SGD+Momentum - Test Accuracy: {test_acc_sgd[-1]:.2f}% | Test Loss: {test_loss_sgd[-1]:.4f}\")"
      ]
    }
  ]
}